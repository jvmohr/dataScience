{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os, datetime, json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = # steam username\n",
    "user_id = # Steam64 id (https://steamid.xyz/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Total Playtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://steamcommunity.com/id/{}/games/?tab=all\".format(username))\n",
    "r.raise_for_status()\n",
    "soup_games = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "for game in soup_games.find_all('script', attrs={'language':'javascript'})[0].contents[0].split('appid'):\n",
    "    if 'TF2' not in game:\n",
    "        continue\n",
    "    data['total_time'] = game.split('hours_forever\":')[1].split(',\"')[0].replace('\"', \"\")\n",
    "    break\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Player Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://steamcommunity.com/id/{}/stats/TF2?tab=stats\".format(username))\n",
    "r.raise_for_status()\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "stuff = soup.find_all('div', attrs={'class':'classExtended'}) # get records for 9 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrs = soup.text.split()\n",
    "cs = soup.find_all('div', class_=\"className\")\n",
    "j = 0\n",
    "classes = {}\n",
    "\n",
    "for i, s in enumerate(hrs):\n",
    "    if 'hrs' in s:\n",
    "        classes[cs[j].text] = {'hours':hrs[i-1]}\n",
    "        j += 1\n",
    "        \n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, info in enumerate(stuff):\n",
    "    for stat in info.find_all('div', class_='personalRecordStat'):\n",
    "        work = stat.text.split()\n",
    "        num = work[-1]\n",
    "        stat_name = \" \".join(work[:-1])\n",
    "        \n",
    "        classes[cs[i].text][stat_name] = num     \n",
    "        \n",
    "classes;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['achievements'] = soup.find_all('div', class_='achievementStatusText')[0].text.split(':')[1].strip()\n",
    "\n",
    "for row in soup.find_all('div', class_='summaryStatRow'):\n",
    "    data[row.text.split(':')[0].strip()] = \" \".join(row.text.split(\":\")[1:]).strip()\n",
    "\n",
    "for row in soup.find('div', attrs={'id':'personalRecords'}).find_all('div', class_='personalRecordStat'):\n",
    "    data[row.find('div', class_='recordStatLabel').text] = row.find('span').text\n",
    "\n",
    "hrsl = str(soup.find('div', attrs={'id':'playtimeBody'})).split('<br/>')\n",
    "data['playtime_two_weeks'] = hrsl[1]\n",
    "data['playtime_on_record'] = hrsl[2].split(\"\\t\")[0]\n",
    "data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grab Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"http://steamcommunity.com/inventory/{}/440/2?l=english&count=5000\".format(user_id))\n",
    "r.raise_for_status()\n",
    "soup_inventory = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf2_inventory = json.loads(soup_inventory.text)\n",
    "tf2_inventory.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['name', 'type', 'market_name', 'tags', 'classid', 'instanceid']\n",
    "strange_items = []\n",
    "\n",
    "for item in tf2_inventory['descriptions']:\n",
    "    if item['tags'][0]['internal_name'] == 'strange':\n",
    "        print(item['type'], item['name'])\n",
    "\n",
    "        strange_item = {}\n",
    "        for key in keys:\n",
    "            try:\n",
    "                strange_item[key] = item[key]\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # filter descriptions list\n",
    "        try:\n",
    "            new_descriptions = []\n",
    "            for value in item['descriptions']:\n",
    "                for test in ['(', 'Killstreak', 'Sheen', 'Halloween']:\n",
    "                    if test in value['value']:\n",
    "                        new_descriptions.append(value['value'])\n",
    "                        break\n",
    "\n",
    "            strange_item['descriptions'] = new_descriptions\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        strange_items.append(strange_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current date\n",
    "today = datetime.datetime.now()\n",
    "new_folder = str(today.month)+\"_\"+str(today.day)+\"_\"+str(today.year)\n",
    "path = os.path.join('data',  new_folder)\n",
    "\n",
    "# Make new folders\n",
    "os.makedirs(path)\n",
    "os.makedirs(os.path.join(path, 'html'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path,'general_data.json'), 'w') as f:\n",
    "    json.dump(data, f)\n",
    "    \n",
    "with open(os.path.join(path,'class_stats.json'), 'w') as f:\n",
    "    json.dump(classes, f)\n",
    "\n",
    "with open(os.path.join(path,'strange_items.json'), 'w') as f:\n",
    "    json.dump(strange_items, f)\n",
    "\n",
    "with open(os.path.join(path, 'html', 'stats.html'), 'w', encoding='utf-8') as f:\n",
    "    f.write(str(soup))\n",
    "    \n",
    "with open(os.path.join(path, 'html', 'inventory.html'), 'w', encoding='utf-8') as f:\n",
    "    f.write(str(soup_inventory))\n",
    "\n",
    "with open(os.path.join(path, 'html', 'games.html'), 'w', encoding='utf-8') as f:\n",
    "    f.write(str(soup_games))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
